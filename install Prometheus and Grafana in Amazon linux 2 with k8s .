install Prometheus and Grafana in Amazon linux 2
-------------------------------------------------------------------------------------------------
Step1 : Launch 3 Amazon Linux 2 ec2 machines(Master, node1 and node2) with t2.large Instance Type
Step2 : Installing Docker and Kubernetes on master
•  vi master.sh
Paste following content in the  master.sh file
===================================================================================================
•  hostnamectl set-hostname K8s-Master
yum update -y
yum install git -y
amazon-linux-extras install java-openjdk11 -y
yum install docker -y
systemctl enable docker	
systemctl restart docker
systemctl status docker
free -mh
sestatus
cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearch
enabled=1
gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kubelet kubeadm kubectl
EOF
sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes
systemctl enable kubelet
systemctl restart kubelet
kubeadm init
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
export KUBECONFIG=/etc/kubernetes/admin.conf
kubeadm token create --print-join-command

===================================================================================================
Give execution permission to master.sh file
• chmod +x master.sh
 
Run the above master.sh file
• ./master.sh
 
Check git version 
•  git –version
 
Check java version
•  java --version
====================================================================================================
Step 3 : Adding node1 and node2 to Kubernetes master
Connect to node1 ec2 machine and Switch to root user
•  sudo -i

Create a file name with node1.sh
•  vi node1.sh
insert the following commands in node1.sh file
=====================================================================================================
•  hostnamectl set-hostname node1
yum update -y
amazon-linux-extras install java-openjdk11 -y
yum install git -y
yum install docker -y
systemctl enable docker
systemctl restart docker
cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearch
enabled=1
gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kubelet kubeadm kubectl
EOF
sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes
systemctl enable kubelet
systemctl restart kubelet
========================================================================================================
Give execution permission to node1.sh file.
•  chmod +x node1.sh
  
Execute the following command in node1.sh file & run it.
•  ./node1.sh

=========================================================================================================
insert the following commands in node2.sh file
Connect to node2 ec2 machine and Switch to root user
•  sudo -i
  
Create a file name with node2.sh
•  vi node2.sh
insert the following commands in node2.sh file
===========================================================================================================
•  hostnamectl set-hostname node2
yum update -y
amazon-linux-extras install java-openjdk11 -y
yum install git -y
yum install docker -y
systemctl enable docker
systemctl restart docker
cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearchenabled=1
gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kubelet kubeadm kubectl
EOF
sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes
systemctl enable kubelet
systemctl restart kubelet
====================================================================================================================
Give execution permission to node2.sh file.
•  chmod +x node2.sh
  
Execute the following command in node2.sh file & run it.
•  ./node2.sh
=====================================================================================================================
Now you can see run that Kubeadm join command on master & copy Kubeadm join command and pest it node1 & node2.
(Execute the join command only on node1 and node 2)

#Execute the command to get the nodes but it shows nodes are NotReady
•  kubectl get nodes

#Run the following commands on master node only. By adding this CNI the all the nodes get ready in our cluster
  
•  curl https://raw.githubusercontent.com/projectcalico/calico/v3.25.0/manifests/calico.yaml -O kubectl apply -f calico.yaml
  
#If all above steps followed correctly the cluster will be created and status will be changed to ready.
•   kubectl get nodes
   
==========================================================================================================================
Now lets clone our project and deploy it on Kubernetes cluster.

#On Master node clone the git repository using the command
#Create a project directory and run git clone command inside it

•   git clone https://github.com/ramdassbhanage/fitpro-k8s-project-new-git2.git
  
#After cloning you will get ready microservices yaml files.You just need to run them.
•   ls
•   cd fitpro-k8s-project-new-git2.git
•   ls

#Run the following command to deploy all the microservices to Kubernetes cluster
•    kubectl apply -f .
----------------------------------------------------------------------------------------------------------------------
#After running apply command project is deployed
#Run the kubectl get pods command to list all pods
•  kubectl get pods

#Run the kubectl get all command to list all the pods and services
•  kubectl get all

#Now run kubecl get svc command to list all ports information
•  kubectl get svc
-------------------------------------------------------------------------------------------------------------- 
#Copy 5 digit port of apigateway service and paste it in the browser with <public ip> of your master machine.
 Example : (http://3.16.169.169:30040/)
 
 ==================================================================================================
Install Prometheus from YUM repository

============================================================================================
• sudo tee /etc/yum.repos.d/prometheus.repo <<EOF 
[prometheus]
name=prometheus
baseurl=https://packagecloud.io/prometheus-rpm/release/el/7/x86_64
repo_gpgcheck=1
enabled=1
gpgkey=https://packagecloud.io/prometheus-rpm/release/gpgkey
       https://raw.githubusercontent.com/lest/prometheus-rpm/master/RPM-GPG-KEY-prometheus-rpm
gpgcheck=1
metadata_expire=300
EOF
=============================================================================================
Install and start prometheus service

• sudo yum -y install prometheus2
• systemctl enable prometheus 
• systemctl restart prometheus 
• systemctl status prometheus 
=============================================================================================
You can use rpm command to check for the version of Prometheus installed.

• rpm -qi prometheus2
=============================================================================================
• sudo vim /etc/prometheus/prometheus.yml

write this all in the file
Note: Replace the localhost With the public IP address

# my global config
global:
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
  - static_configs:
    - targets:
      # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'K8s-master'

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
    - targets: ['localhost:9090']     
  # Pull host metrics with node exporter
  - job_name: ‘Worker-node’
    static_configs:
      - targets: ['localhost:9100']
=================================================================================================
Restart the prometheus

• systemctl restart prometheus
• systemctl enable prometheus  
• systemctl status prometheus 
=================================================================================================
Install node exporter 

• yum -y install node_exporter
• systemctl enable node_exporter 
• systemctl restart node_exporter 
• systemctl status node_exporter 
=================================================================================================
• for the prometheus dashboard

http://(server_hostname_or_IP_Address):9090/
=================================================================================================
• for getting the metrics from the node exporter

http://(server_hostname_or_IP_Address):9100/

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Install the node_exporter on the worker node also

• yum -y install node_exporter
• systemctl enable node_exporter 
• systemctl start node_exporter 
• systemctl status node_exporter 
==================================================================================================
